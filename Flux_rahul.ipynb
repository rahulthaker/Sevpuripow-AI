{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyO6zCwO71HpdBJtFSlMKzlE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulthaker/Sevpuripow-AI/blob/main/Flux_rahul.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7c1AnybKOV4",
        "outputId": "934d5301-3534-4bb3-8529-cffb4850c311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Mount Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "#@markdown Mount Google Drive to Save Datasets and Results\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define custom save paths in Google Drive\n",
        "dataset_path = \"/content/drive/MyDrive/sevpuripow_Dataset\"  #@param {type:\"string\"}\n",
        "results_path = \"/content/drive/MyDrive/sevpuripow_Results\"  #@param {type:\"string\"}\n",
        "\n",
        "# Create directories in Google Drive if they don't exist\n",
        "!mkdir -p {dataset_path}\n",
        "!mkdir -p {results_path}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clone the repository and install the necessary dependencies\n",
        "!git clone https://github.com/ostris/ai-toolkit\n",
        "!cd ai-toolkit && git submodule update --init --recursive && pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bs9goJTcKk05",
        "outputId": "1467d374-7e30-4c77-9dc6-4586d609329f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ai-toolkit'...\n",
            "remote: Enumerating objects: 3753, done.\u001b[K\n",
            "remote: Counting objects: 100% (3752/3752), done.\u001b[K\n",
            "remote: Compressing objects: 100% (896/896), done.\u001b[K\n",
            "remote: Total 3753 (delta 2863), reused 3622 (delta 2770), pack-reused 1 (from 1)\u001b[K\n",
            "Receiving objects: 100% (3753/3753), 29.65 MiB | 43.19 MiB/s, done.\n",
            "Resolving deltas: 100% (2863/2863), done.\n",
            "Submodule 'repositories/batch_annotator' (https://github.com/ostris/batch-annotator) registered for path 'repositories/batch_annotator'\n",
            "Submodule 'repositories/ipadapter' (https://github.com/tencent-ailab/IP-Adapter.git) registered for path 'repositories/ipadapter'\n",
            "Submodule 'repositories/leco' (https://github.com/p1atdev/LECO) registered for path 'repositories/leco'\n",
            "Submodule 'repositories/sd-scripts' (https://github.com/kohya-ss/sd-scripts.git) registered for path 'repositories/sd-scripts'\n",
            "Cloning into '/content/ai-toolkit/repositories/batch_annotator'...\n",
            "Cloning into '/content/ai-toolkit/repositories/ipadapter'...\n",
            "Cloning into '/content/ai-toolkit/repositories/leco'...\n",
            "Cloning into '/content/ai-toolkit/repositories/sd-scripts'...\n",
            "Submodule path 'repositories/batch_annotator': checked out '420e142f6ad3cc14b3ea0500affc2c6c7e7544bf'\n",
            "Submodule 'repositories/controlnet' (https://github.com/lllyasviel/ControlNet-v1-1-nightly.git) registered for path 'repositories/batch_annotator/repositories/controlnet'\n",
            "Cloning into '/content/ai-toolkit/repositories/batch_annotator/repositories/controlnet'...\n",
            "Submodule path 'repositories/batch_annotator/repositories/controlnet': checked out 'e2b44154b72965c5e11b1ccee941d550682e4701'\n",
            "Submodule path 'repositories/ipadapter': checked out '5a18b1f3660acaf8bee8250692d6fb3548a19b14'\n",
            "Submodule path 'repositories/leco': checked out '9294adf40218e917df4516737afb13f069a6789d'\n",
            "Submodule path 'repositories/sd-scripts': checked out 'b78c0e2a69e52ce6c79abc6c8c82d1a9cabcf05c'\n",
            "Collecting git+https://github.com/huggingface/diffusers.git (from -r requirements.txt (line 4))\n",
            "  Cloning https://github.com/huggingface/diffusers.git to /tmp/pip-req-build-vcgnpn0y\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers.git /tmp/pip-req-build-vcgnpn0y\n",
            "  Resolved https://github.com/huggingface/diffusers.git to commit aa73072f1f7014635e3de916cbcf47858f4c37a0\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.19.1+cu121)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.4.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (4.44.2)\n",
            "Collecting lycoris-lora==1.8.3 (from -r requirements.txt (line 6))\n",
            "  Downloading lycoris_lora-1.8.3.tar.gz (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m988.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flatten_json (from -r requirements.txt (line 7))\n",
            "  Downloading flatten_json-0.1.14-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.2)\n",
            "Collecting oyaml (from -r requirements.txt (line 9))\n",
            "  Downloading oyaml-1.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (2.17.0)\n",
            "Collecting kornia (from -r requirements.txt (line 11))\n",
            "  Downloading kornia-0.7.3-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting invisible-watermark (from -r requirements.txt (line 12))\n",
            "  Downloading invisible_watermark-0.2.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (0.8.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.34.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (0.10.2)\n",
            "Requirement already satisfied: albumentations==1.4.15 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (1.4.15)\n",
            "Requirement already satisfied: albucore==0.0.16 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (0.0.16)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (2.9.2)\n",
            "Collecting omegaconf (from -r requirements.txt (line 19))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting k-diffusion (from -r requirements.txt (line 20))\n",
            "  Downloading k_diffusion-0.1.1.post1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting open_clip_torch (from -r requirements.txt (line 21))\n",
            "  Downloading open_clip_torch-2.26.1-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting timm (from -r requirements.txt (line 22))\n",
            "  Downloading timm-1.0.9-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prodigyopt (from -r requirements.txt (line 23))\n",
            "  Downloading prodigyopt-1.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting controlnet_aux==0.0.7 (from -r requirements.txt (line 24))\n",
            "  Downloading controlnet_aux-0.0.7.tar.gz (202 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.4/202.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-dotenv (from -r requirements.txt (line 25))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting bitsandbytes (from -r requirements.txt (line 26))\n",
            "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting hf_transfer (from -r requirements.txt (line 27))\n",
            "  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting lpips (from -r requirements.txt (line 28))\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pytorch_fid (from -r requirements.txt (line 29))\n",
            "  Downloading pytorch_fid-0.3.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting optimum-quanto (from -r requirements.txt (line 30))\n",
            "  Downloading optimum_quanto-0.2.4-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 31)) (0.1.99)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 32)) (0.24.7)\n",
            "Collecting peft (from -r requirements.txt (line 33))\n",
            "  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 34))\n",
            "  Downloading gradio-4.44.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (8.0.4)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (1.13.1)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (0.23.2)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.4.15->-r requirements.txt (line 16)) (4.10.0.84)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.10/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (8.5.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (4.10.0.84)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (3.16.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from controlnet_aux==0.0.7->-r requirements.txt (line 24)) (10.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 1)) (2024.6.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.31.0.dev0->-r requirements.txt (line 4)) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.31.0.dev0->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (24.1)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 5)) (4.66.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from flatten_json->-r requirements.txt (line 7)) (1.16.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (71.0.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 10)) (3.0.4)\n",
            "Collecting kornia-rs>=0.1.0 (from kornia->-r requirements.txt (line 11))\n",
            "  Downloading kornia_rs-0.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.7 kB)\n",
            "Collecting PyWavelets>=1.1.1 (from invisible-watermark->-r requirements.txt (line 12))\n",
            "  Downloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 14)) (5.9.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->-r requirements.txt (line 18)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->-r requirements.txt (line 18)) (2.23.4)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->-r requirements.txt (line 19))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting clean-fid (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting clip-anytorch (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading clip_anytorch-2.6.0-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting dctorch (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading dctorch-0.1.2-py3-none-any.whl.metadata (607 bytes)\n",
            "Collecting jsonmerge (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading jsonmerge-1.9.2-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting torchdiffeq (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading torchdiffeq-0.2.4-py3-none-any.whl.metadata (440 bytes)\n",
            "Collecting torchsde (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting wandb (from k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading wandb-0.18.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting ftfy (from open_clip_torch->-r requirements.txt (line 21))\n",
            "  Downloading ftfy-6.2.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting ninja (from optimum-quanto->-r requirements.txt (line 30))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (3.7.1)\n",
            "Collecting fastapi<1.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (6.4.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (2.1.4)\n",
            "Collecting pydub (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading python_multipart-0.0.10-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading ruff-0.6.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (0.12.5)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 34)) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 34))\n",
            "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio->-r requirements.txt (line 34))\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->-r requirements.txt (line 35)) (1.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 34)) (1.2.2)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi<1.0->gradio->-r requirements.txt (line 34))\n",
            "  Downloading starlette-0.38.5-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 34)) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio->-r requirements.txt (line 34))\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 34))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 34)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 34)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 34)) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 34)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 34)) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 34)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 34)) (2024.1)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (2024.8.30)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.15->-r requirements.txt (line 16)) (0.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (13.8.1)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->open_clip_torch->-r requirements.txt (line 21)) (0.2.13)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata->controlnet_aux==0.0.7->-r requirements.txt (line 24)) (3.20.2)\n",
            "Requirement already satisfied: jsonschema>2.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonmerge->k-diffusion->-r requirements.txt (line 20)) (4.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.31.0.dev0->-r requirements.txt (line 4)) (3.3.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Collecting trampoline>=0.1.2 (from torchsde->k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb->k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->k-diffusion->-r requirements.txt (line 20)) (4.3.6)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading sentry_sdk-2.14.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting setproctitle (from wandb->k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>2.4.0->jsonmerge->k-diffusion->-r requirements.txt (line 20)) (0.20.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (2.18.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->k-diffusion->-r requirements.txt (line 20))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 34)) (0.1.2)\n",
            "Downloading flatten_json-0.1.14-py3-none-any.whl (8.0 kB)\n",
            "Downloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
            "Downloading kornia-0.7.3-py2.py3-none-any.whl (833 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m833.3/833.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading invisible_watermark-0.2.0-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading k_diffusion-0.1.1.post1-py3-none-any.whl (33 kB)\n",
            "Downloading open_clip_torch-2.26.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prodigyopt-1.0-py3-none-any.whl (5.5 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_fid-0.3.0-py3-none-any.whl (15 kB)\n",
            "Downloading optimum_quanto-0.2.4-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.7/109.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-4.44.0-py3-none-any.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.0-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia_rs-0.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.10-py3-none-any.whl (22 kB)\n",
            "Downloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruff-0.6.7-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading clean_fid-0.1.35-py3-none-any.whl (26 kB)\n",
            "Downloading clip_anytorch-2.6.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dctorch-0.1.2-py3-none-any.whl (2.3 kB)\n",
            "Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading ftfy-6.2.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonmerge-1.9.2-py3-none-any.whl (19 kB)\n",
            "Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading torchdiffeq-0.2.4-py3-none-any.whl (32 kB)\n",
            "Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.18.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.14.0-py2.py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.4/311.4 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.38.5-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: lycoris-lora, controlnet_aux, diffusers, antlr4-python3-runtime\n",
            "  Building wheel for lycoris-lora (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lycoris-lora: filename=lycoris_lora-1.8.3-py3-none-any.whl size=77134 sha256=1598167ce7028288b9f7c3934c11ec2362958228b4b65c9e0a7cf80eaa061478\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/d8/ac/e1feba5dec18685dac32ff2465ea1908cbe6a919a0c008a215\n",
            "  Building wheel for controlnet_aux (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for controlnet_aux: filename=controlnet_aux-0.0.7-py3-none-any.whl size=274342 sha256=1d2b0d362d77a271f5db3eec1a908a26b72ce1de03a8da88aedf68139b9e6085\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/3e/93/6678b4c0bc2ec31d53409b25d4189cbb08bae843e8b2b78e52\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.31.0.dev0-py3-none-any.whl size=2772797 sha256=aa5042a57b8b51e85c705a675ce3e513b9d765925631a40d479770f08f399b05\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2ntbhc65/wheels/4d/b7/a8/6f9549ceec5daad78675b857ac57d697c387062506520a7b50\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=48c4c2ba143b11adf3b429112158e3b1a2dc9a445b27d268485c90b254b37ed9\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built lycoris-lora controlnet_aux diffusers antlr4-python3-runtime\n",
            "Installing collected packages: trampoline, pydub, ninja, antlr4-python3-runtime, websockets, tomlkit, smmap, setproctitle, sentry-sdk, semantic-version, ruff, PyWavelets, python-multipart, python-dotenv, prodigyopt, oyaml, orjson, omegaconf, kornia-rs, hf_transfer, h11, ftfy, flatten_json, ffmpy, docker-pycreds, aiofiles, uvicorn, starlette, httpcore, gitdb, torchsde, torchdiffeq, optimum-quanto, kornia, invisible-watermark, httpx, gitpython, fastapi, diffusers, dctorch, bitsandbytes, wandb, timm, pytorch_fid, lpips, jsonmerge, gradio-client, clip-anytorch, clean-fid, peft, open_clip_torch, lycoris-lora, k-diffusion, gradio, controlnet_aux\n",
            "Successfully installed PyWavelets-1.7.0 aiofiles-23.2.1 antlr4-python3-runtime-4.9.3 bitsandbytes-0.43.3 clean-fid-0.1.35 clip-anytorch-2.6.0 controlnet_aux-0.0.7 dctorch-0.1.2 diffusers-0.31.0.dev0 docker-pycreds-0.4.0 fastapi-0.115.0 ffmpy-0.4.0 flatten_json-0.1.14 ftfy-6.2.3 gitdb-4.0.11 gitpython-3.1.43 gradio-4.44.0 gradio-client-1.3.0 h11-0.14.0 hf_transfer-0.1.8 httpcore-1.0.5 httpx-0.27.2 invisible-watermark-0.2.0 jsonmerge-1.9.2 k-diffusion-0.1.1.post1 kornia-0.7.3 kornia-rs-0.1.5 lpips-0.1.4 lycoris-lora-1.8.3 ninja-1.11.1.1 omegaconf-2.3.0 open_clip_torch-2.26.1 optimum-quanto-0.2.4 orjson-3.10.7 oyaml-1.0 peft-0.12.0 prodigyopt-1.0 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.10 pytorch_fid-0.3.0 ruff-0.6.7 semantic-version-2.10.0 sentry-sdk-2.14.0 setproctitle-1.3.3 smmap-5.0.1 starlette-0.38.5 timm-1.0.9 tomlkit-0.12.0 torchdiffeq-0.2.4 torchsde-0.2.6 trampoline-0.1.2 uvicorn-0.30.6 wandb-0.18.1 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set Hugging Face Token\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "#@markdown ### Enter your Hugging Face Token\n",
        "hf_token = getpass.getpass('Enter your Hugging Face access token and press enter: ')\n",
        "os.environ['HF_TOKEN'] = hf_token\n",
        "print(\"HF_TOKEN environment variable has been set.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoLn1slOLBGG",
        "outputId": "516633dc-9437-4d64-fb8c-092b1e24b9a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your Hugging Face access token and press enter: ··········\n",
            "HF_TOKEN environment variable has been set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Dependencies\n",
        "import sys\n",
        "from collections import OrderedDict\n",
        "\n",
        "sys.path.append('/content/ai-toolkit')\n",
        "from toolkit.job import run_job"
      ],
      "metadata": {
        "id": "PAmpd2I0PnH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configure Training Job\n",
        "\n",
        "#@markdown This name will be the folder and filename name\n",
        "job_name = \"sevpuripow_lora_v1\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Trigger word will be added to captions if it does not already exist\n",
        "trigger_word = \"sevpuripow\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Number of images processed in each training step\n",
        "batch_size = 1  #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Total number of steps to train; 500 - 4000 is a good range\n",
        "steps = 3000  #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Learning rate for training the model\n",
        "learning_rate = 4e-4  #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Save every this many steps\n",
        "save_every = 250  #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown How many intermittent saves to keep\n",
        "max_step_saves_to_keep = 6  #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Sample every this many steps\n",
        "sample_every = 250  #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown Higher guidance scale may improve image quality but could reduce diversity\n",
        "guidance_scale = 4  #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Number of diffusion steps used for sampling\n",
        "sample_steps = 20  #@param {type:\"integer\"}\n",
        "\n",
        "#@markdown ### Enter Your Prompts\n",
        "\n",
        "#@markdown (Prompt for generating sample images)\n",
        "sample_prompt_1 = \"sevpuripow man with flowing silver hair, standing on a cliff, overlooking a stormy sea, with lightning striking in the distance\"  #@param {type:\"string\"}\n",
        "\n",
        "sample_prompt_2 = \"sevpuipow man, proud in a futuristic cityscape at night, neon lights illuminating the streets, flying cars zooming by, people walking with holographic umbrellas\"  #@param {type:\"string\"}\n",
        "\n",
        "sample_prompt_3 = \"sevpuripow man is a samurai warrior in traditional armor, standing under cherry blossom trees in full bloom, with petals falling around them\"  #@param {type:\"string\"}\n",
        "\n",
        "sample_prompt_4 = \"sevpuripow man as a chef preparing a gourmet meal in a high-tech kitchen, steam rising from the pots, with intricate plating on a futuristic table\"  #@param {type:\"string\"}\n",
        "\n",
        "sample_prompt_5 = \"sevpuripow man is a detective in a rain-soaked alley, under a flickering streetlight, holding an old-fashioned revolver, with a shadowy figure in the distance\"  #@param {type:\"string\"}\n",
        "\n",
        "sample_prompt_6 = \"sevpuripow man is a DJ on a floating stage in space, with planets and stars in the background, cosmic dust swirling around\"  #@param {type:\"string\"}\n",
        "\n",
        "sample_prompt_7 = \"sevpuripow man is a A data scientist wearing a Caterpillar-branded hard hat, standing next to massive construction machinery, analyzing complex datasets on a rugged tablet. Charts and graphs display engine performance. The scene is set in a bustling construction site, with yellow and black machines operating in the background, while the worker uses advanced AI algorithms to enhance productivity and optimize machinery efficiency\"  #@param {type:\"string\"}\n",
        "\n",
        "sample_prompt_8 = \"sevpuripow man is standing next to Deadpool in the vibrant streets of Mumbai, with bustling traffic, colorful market stalls, and the iconic Gateway of India in the background. Deadpool strikes a comical pose while the person, dressed casually, shares a light-hearted moment with him. The city skyline, with tall buildings and busy streets, is illuminated by the setting sun, casting a warm glow over the scene\"  #@param {type:\"string\"}\n",
        "\n",
        "# Generate a list of prompts based on non-empty inputs\n",
        "sample_prompts = [prompt for prompt in [\n",
        "    sample_prompt_1,\n",
        "    sample_prompt_2,\n",
        "    sample_prompt_3,\n",
        "    sample_prompt_4,\n",
        "    sample_prompt_5,\n",
        "    sample_prompt_6,\n",
        "    sample_prompt_7,\n",
        "    sample_prompt_8\n",
        "] if prompt.strip()]\n",
        "\n",
        "# Displaying the active prompts\n",
        "print(\"Active prompts:\", sample_prompts)"
      ],
      "metadata": {
        "id": "1O725pawPnQJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c6df81-ee08-48f9-8379-792f99f872e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Active prompts: ['sevpuripow man with flowing silver hair, standing on a cliff, overlooking a stormy sea, with lightning striking in the distance', 'sevpuipow man, proud in a futuristic cityscape at night, neon lights illuminating the streets, flying cars zooming by, people walking with holographic umbrellas', 'sevpuripow man is a samurai warrior in traditional armor, standing under cherry blossom trees in full bloom, with petals falling around them', 'sevpuripow man as a chef preparing a gourmet meal in a high-tech kitchen, steam rising from the pots, with intricate plating on a futuristic table', 'sevpuripow man is a detective in a rain-soaked alley, under a flickering streetlight, holding an old-fashioned revolver, with a shadowy figure in the distance', 'sevpuripow man is a DJ on a floating stage in space, with planets and stars in the background, cosmic dust swirling around', 'sevpuripow man is a A data scientist wearing a Caterpillar-branded hard hat, standing next to massive construction machinery, analyzing complex datasets on a rugged tablet. Charts and graphs display engine performance. The scene is set in a bustling construction site, with yellow and black machines operating in the background, while the worker uses advanced AI algorithms to enhance productivity and optimize machinery efficiency', 'sevpuripow man is standing next to Deadpool in the vibrant streets of Mumbai, with bustling traffic, colorful market stalls, and the iconic Gateway of India in the background. Deadpool strikes a comical pose while the person, dressed casually, shares a light-hearted moment with him. The city skyline, with tall buildings and busy streets, is illuminated by the setting sun, casting a warm glow over the scene']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Job Configuration Setup\n",
        "\n",
        "from collections import OrderedDict\n",
        "\n",
        "job_to_run = OrderedDict([\n",
        "    ('job', 'extension'),\n",
        "    ('config', OrderedDict([\n",
        "        ('name', job_name),  # this name will be the folder and filename name\n",
        "        ('process', [\n",
        "            OrderedDict([\n",
        "                ('type', 'sd_trainer'),\n",
        "                ('training_folder', results_path),  # root folder to save training sessions/samples/weights\n",
        "                # Uncomment the line below to see performance stats in the terminal every N steps\n",
        "                # ('performance_log_every', 1000),\n",
        "                ('device', 'cuda:0'),  # use GPU device for training\n",
        "                ('trigger_word', trigger_word),  # trigger word for training data or use [trigger] in captions\n",
        "                ('network', OrderedDict([\n",
        "                    ('type', 'lora'),  # using LoRA (Low-Rank Adaptation) for fine-tuning\n",
        "                    ('linear', 16),  # hyperparameter for LoRA\n",
        "                    ('linear_alpha', 16)  # hyperparameter for LoRA\n",
        "                ])),\n",
        "                ('save', OrderedDict([\n",
        "                    ('dtype', 'float16'),  # precision to save; float16 reduces memory usage\n",
        "                    ('save_every', save_every),  # save every this many steps\n",
        "                    ('max_step_saves_to_keep', max_step_saves_to_keep)  # how many intermittent saves to keep\n",
        "                ])),\n",
        "                ('datasets', [\n",
        "                    OrderedDict([\n",
        "                        ('folder_path', dataset_path),  # path to dataset in Google Drive\n",
        "                        ('caption_ext', 'txt'),  # caption files should have the same name as images with .txt extension\n",
        "                        ('caption_dropout_rate', 0.05),  # will drop out the caption 5% of the time to encourage robustness\n",
        "                        ('shuffle_tokens', False),  # shuffle caption order, split by commas\n",
        "                        ('cache_latents_to_disk', True),  # cache latents to disk, recommended to leave true\n",
        "                        ('resolution', [512, 768, 1024])  # flux enjoys multiple resolutions for better training\n",
        "                    ])\n",
        "                ]),\n",
        "                ('train', OrderedDict([\n",
        "                    ('batch_size', batch_size),  # number of images processed in each training step\n",
        "                    ('steps', steps),  # total number of steps to train; 500 - 4000 is a good range\n",
        "                    ('gradient_accumulation_steps', 1),  # accumulate gradients over multiple steps before updating weights\n",
        "                    ('train_unet', True),  # train the U-Net part of the model\n",
        "                    ('train_text_encoder', False),  # probably won't work with flux; keep it False\n",
        "                    ('content_or_style', 'balanced'),  # choose between content, style, or balanced training\n",
        "                    ('gradient_checkpointing', True),  # keep this on unless you have a ton of VRAM\n",
        "                    ('noise_scheduler', 'flowmatch'),  # must match the training noise scheduler\n",
        "                    ('optimizer', 'adamw8bit'),  # use 8-bit Adam optimizer for better memory efficiency\n",
        "                    ('lr', learning_rate),  # learning rate for training the model\n",
        "                    # Uncomment the line below to skip the pre-training sample\n",
        "                    # ('skip_first_sample', True),\n",
        "                    ('ema_config', OrderedDict([\n",
        "                        ('use_ema', True),  # EMA will smooth out learning but could slow it down; recommended to leave on\n",
        "                        ('ema_decay', 0.99)  # decay rate for EMA\n",
        "                    ])),\n",
        "                    ('dtype', 'bf16')  # use bfloat16 for better performance on supported GPUs\n",
        "                ])),\n",
        "                ('model', OrderedDict([\n",
        "                    ('name_or_path', 'black-forest-labs/FLUX.1-dev'),  # Hugging Face model name or path\n",
        "                    ('is_flux', True),  # indicates that the model is based on FLUX architecture\n",
        "                    ('quantize', True),  # run 8-bit mixed precision for reduced memory usage\n",
        "                    # Uncomment the line below if the GPU is connected to your monitors; it will use less VRAM but is slower\n",
        "                    # ('low_vram', True),\n",
        "                ])),\n",
        "                ('sample', OrderedDict([\n",
        "                    ('sampler', 'flowmatch'),  # must match training noise scheduler\n",
        "                    ('sample_every', sample_every),  # sample every this many steps\n",
        "                    ('width', 1024),  # width of the generated images\n",
        "                    ('height', 1024),  # height of the generated images\n",
        "                    ('prompts', sample_prompts),  # list of prompts for generating images\n",
        "                    ('neg', ''),  # unused for FLUX; keep as an empty string\n",
        "                    ('seed', 42),  # random seed for reproducibility\n",
        "                    ('walk_seed', True),  # use a different seed for each sampling step\n",
        "                    ('guidance_scale', guidance_scale),  # higher guidance scale can improve image quality but reduce diversity\n",
        "                    ('sample_steps', sample_steps)  # number of diffusion steps used for sampling\n",
        "                ]))\n",
        "            ])\n",
        "        ])\n",
        "    ])),\n",
        "    ('meta', OrderedDict([\n",
        "        ('name', job_name),  # metadata for the job, including the name\n",
        "        ('version', '1.0')  # version of the job configuration\n",
        "    ]))\n",
        "])"
      ],
      "metadata": {
        "id": "af_ZW5FDSygS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Training Job\n",
        "\n",
        "run_job(job_to_run)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "h7bXw_E7T8Hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VQ6eCupIJZmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running the output**\n"
      ],
      "metadata": {
        "id": "7SVBxu8oJa55"
      }
    }
  ]
}